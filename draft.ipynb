{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "import xai\n",
    "import numpy as np\n",
    "import dill\n",
    "import pickle\n",
    "import inspect\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "X = TypeVar(\"X\")\n",
    "Y = TypeVar(\"Y\")\n",
    "\n",
    "class Stream(Generic[X]):\n",
    "\n",
    "    def __init__(self, source: Iterable[X]) -> None:\n",
    "        super().__init__()\n",
    "        self._parent: Stream[Any]|None = None\n",
    "        self._source = source\n",
    "\n",
    "    def map(self, f: Callable[[X],Y]) -> \"Stream[Y]\":\n",
    "        return self._appended(f(x) for x in self)\n",
    "    \n",
    "    def fork(self, processes: int) -> \"Stream[Y]\":\n",
    "        assert processes > 0\n",
    "        if processes == 0:\n",
    "            return self\n",
    "        else:\n",
    "            with mp.Pool(processes) as pool:\n",
    "                pool.join()\n",
    "\n",
    "    \n",
    "    def foreach(self, f: Callable[[X],Y]) -> None:\n",
    "        for x in self:\n",
    "            f(x)\n",
    "\n",
    "    def _appended(self, source: Iterable[Y]) -> \"Stream[Y]\":\n",
    "        stream = Stream(source)\n",
    "        stream._parent = self\n",
    "        return stream \n",
    "    \n",
    "    def __iter__(self) -> Iterator[X]:\n",
    "        return iter(self._source)\n",
    "    \n",
    "\n",
    "Stream([1,2,3]).foreach(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dir(type(\"\".join))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(\"\".join).__call__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = iter(i for i in range(10))\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "queue = mp.Queue()\n",
    "\n",
    "foo = mp.Process(target=lambda n,queue: queue.put(n), args=(2,queue))\n",
    "bar = mp.Process(target=lambda n,queue: [queue.put(i) for i in range(n)], args=(30,queue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo.start()\n",
    "bar.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 21)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue.get(), queue.qsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "\n",
    "def add(n):\n",
    "    return n+2\n",
    "\n",
    "def fetch():\n",
    "    for i in range(100000):\n",
    "        print(\"fetch\")\n",
    "        yield i\n",
    "\n",
    "with ThreadPoolExecutor(10) as tp:\n",
    "    for res in tp.map(add, fetch(), chunksize=2):\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xai.Stream.sample(range(100), with_replacement=True)\n",
    " .take(1000000)\n",
    " .map(lambda n: f\"int:{n}\"*10)\n",
    " .monitor(\"Random sampling\")\n",
    " .save(\"numbers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(xai.Stream.load(\"numbers\", str).drop(1).monitor().list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xai.Stream.load(\"asteroids-l32.pt\", xai.AutoEncoder).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(xai.Stream.load(\"asteroids-l32.pt\", xai.AutoEncoder)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xai.Stream([]).fork(lambda s: (\n",
    "    s.map(lambda n: 2).fork(),\n",
    "    s.map()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import sys\n",
    "f = lambda n: 2\n",
    "\n",
    "f.__setstate__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda n: 2\n",
    "f.__getstate__ = lambda self: dill.dumps(self)\n",
    "f.__setstate__ = lambda self: dill.dumps(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dump = pickle.dumps(type(\"Foo\", tuple(), {\n",
    "    \"__call__\": lambda self: 2\n",
    "})())\n",
    "dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = dill.loads(dump)\n",
    "load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "from IPython.display import DisplayObject\n",
    "from dataclasses import dataclass\n",
    "from plotly.graph_objects import Figure # type: ignore\n",
    "\n",
    "import plotly.express as px # type: ignore\n",
    "\n",
    "class TrainRecord(NamedTuple):\n",
    "    batch_size: int\n",
    "    train_loss: float\n",
    "    val_loss:   float|None\n",
    "    accuracy:   float|None\n",
    "    info:       str|None\n",
    "\n",
    "class TrainHistory(list[TrainRecord]):\n",
    "\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        for key,value in vars(self.figure()).items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    def append_epoch(self,\n",
    "                     batch_size: int,\n",
    "                     train_loss: float,\n",
    "                     val_loss:   float|None = None,\n",
    "                     accuracy:   float|None = None,\n",
    "                     info:       str|None = None) -> None:\n",
    "        self.append(TrainRecord(\n",
    "            batch_size=batch_size,\n",
    "            train_loss=train_loss,\n",
    "            val_loss=val_loss,\n",
    "            accuracy=accuracy,\n",
    "            info=info\n",
    "        ))\n",
    "\n",
    "    def figure(self) -> Figure:\n",
    "        if not self:\n",
    "            return px.line({})\n",
    "        \n",
    "        last_info = self[0].info\n",
    "        \n",
    "        milestones: list[tuple[str,dict[str,int]]] = [(last_info, {})]\n",
    "        \n",
    "        for epoch,record in enumerate(self):\n",
    "            if last_info != record.info:\n",
    "                milestones.append((record.info,{}))\n",
    "\n",
    "            for stat in record:\n",
    "                pass\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "        return px.line({\"x\": []}, x=\"x\")\n",
    "    \n",
    "    def _ipython_display_(self):\n",
    "        return self.figure()._ipython_display_()\n",
    "    \n",
    "TrainHistory([TrainRecord(54,34,23,1,\"\"),TrainRecord(54,34,23,1,\"\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
