{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "np.set_printoptions(formatter={'float': '{: 0.4f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = 3\n",
    "classes = 1\n",
    "\n",
    "encoder = torch.nn.Sequential(\n",
    "    torch.nn.Linear(features,5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(5,5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(5,classes),\n",
    ")\n",
    "\n",
    "decoder = torch.nn.Sequential(\n",
    "    torch.nn.Linear(classes,5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(5,5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(5,features)\n",
    ")\n",
    "\n",
    "optim = torch.optim.Adam((encoder + decoder).parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.zeros((10_000,3), dtype=torch.float32, device=\"cpu\")\n",
    "X[:,0] = torch.rand((10_000,))\n",
    "X[:,1] = X[:,0]*2\n",
    "X[:,2] = X[:,1]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00000: 100%|██████████| 10000/10000 [01:10<00:00, 141.47it/s]\n"
     ]
    }
   ],
   "source": [
    "bar = tqdm(range(10_000))\n",
    "for epoch in bar:\n",
    "    optim.zero_grad()\n",
    "    x = X[torch.randperm(len(X), device=\"cpu\")[:1000]]\n",
    "    x_hat: torch.Tensor = (encoder + decoder)(x)\n",
    "    loss: torch.Tensor = torch.mean((x_hat - x)**2)\n",
    "    bar.set_description(f\"Loss: {loss:.5f}\")\n",
    "    loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap.maskers\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    with torch.no_grad():\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.from_numpy(x).float()\n",
    "\n",
    "        return encoder(x).numpy(force=True)\n",
    "\n",
    "        \n",
    "explainer = shap.ExactExplainer(f, shap.maskers.Independent(X.numpy(force=True), 1000))\n",
    "\n",
    "def f_inv(x):\n",
    "    with torch.no_grad():\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.from_numpy(x).float()\n",
    "            \n",
    "        return decoder(x).numpy(force=True)\n",
    "        \n",
    "explainer_inv = shap.ExactExplainer(f_inv, shap.maskers.Independent(encoder(X).numpy(force=True), 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3834, 0.7668, 1.5335]]),\n",
       " tensor([[3.7061]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[0.3837, 0.7671, 1.5340]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = torch.randint(0,len(X),(1,))\n",
    "X[idx], encoder(X[idx]), decoder(encoder(X[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".values =\n",
       "array([[-0.0674, -0.4815, -0.5104]])\n",
       "\n",
       ".base_values =\n",
       "array([[ 4.7655]])\n",
       "\n",
       ".data =\n",
       "array([[ 0.3834,  0.7668,  1.5335]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp: shap.Explanation = explainer(X[idx:idx+1].numpy(force=True))\n",
    "exp_values = exp.values.reshape((features,classes))\n",
    "exp_base_values = exp.base_values.reshape((classes))\n",
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".values =\n",
       "array([[[-0.1059, -0.2115, -0.4230]]])\n",
       "\n",
       ".base_values =\n",
       "array([[ 0.4896,  0.9786,  1.9570]])\n",
       "\n",
       ".data =\n",
       "array([[ 3.7061]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_exp: shap.Explanation = explainer_inv(encoder(X[idx:idx+1]).numpy(force=True))\n",
    "inv_exp_values = inv_exp.values.reshape((features,classes))\n",
    "inv_exp_base_values = inv_exp.base_values.reshape((features))\n",
    "inv_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.0594])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_values.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = ((inv_exp_values.T - X[idx].numpy(force=True) + inv_exp_base_values) + f(X[idx:idx+1]) - exp_base_values).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.0591, -1.0591, -1.0589])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0636, -0.4545, -0.4818])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_importance = (exp.values/np.sum(abs(exp.values), axis=1))[0]\n",
    "encoder_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1430, -0.2857, -0.5713]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_importance = (inv_exp.values/np.sum(abs(inv_exp.values), axis=2))[0]\n",
    "decoder_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mencoder_importance\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, decoder_importance[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "encoder_importance[0,0], decoder_importance[0,0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
