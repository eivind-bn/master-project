{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xai import *\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new agent...\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "try:\n",
    "    dqn = DQN.load(\"git-ignore/dqn-model.pt\", device=device)\n",
    "except FileNotFoundError:\n",
    "    print(\"Creating new agent...\")\n",
    "    dqn = DQN(autoencoder_path=\"git-ignore/asteroids-autoencoder-l32.pt\", translate=True, rotate=True, device=device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.train(\n",
    "    total_time_steps=1_000_000,\n",
    "    max_episodes=201,\n",
    "    replay_buffer_size=int(5e6),\n",
    "    learning_rate = 1e-4,\n",
    "    learning_starts = 3*6500,\n",
    "    batch_size = 64,\n",
    "    tau = 1.0,\n",
    "    gamma = 0.99,\n",
    "    train_frequency = 64,\n",
    "    frame_skip=4,\n",
    "    gradient_steps = 1,\n",
    "    episode_save_freq= 25,\n",
    "    target_update_frequency = 2000,\n",
    "    final_exploration_rate_progress = 1.0,\n",
    "    initial_exploration_rate = 0.2898721500000001,\n",
    "    final_exploration_rate = 0.05,\n",
    "    verbose = True,\n",
    "    save_path=\"git-ignore/dqn-model.pt\",\n",
    "    q_value_head_background_path=\"git-ignore/states.npy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=250)\n",
    "plt.title(\"Rewards per episode\")\n",
    "plt.plot(range(len(dqn.rewards_per_episode)), dqn.rewards_per_episode, label=\"Total reward\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Reward\")\n",
    "\n",
    "avg_rewards = []\n",
    "\n",
    "for i in range(len(dqn.rewards_per_episode)):\n",
    "    avg = []\n",
    "    for i,reward in enumerate(dqn.rewards_per_episode[max(0,i-4):min(i+5, len(dqn.rewards_per_episode))]):\n",
    "        avg.append(reward)\n",
    "    avg_rewards.append(sum(avg)/len(avg))\n",
    "\n",
    "plt.plot(range(len(avg_rewards)), avg_rewards, label=\"Moving average reward\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=250)\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Rewards versus exploration correlation\")\n",
    "plt.plot(range(len(dqn.rewards_per_episode)), dqn.rewards_per_episode, label=\"Total reward\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.plot(range(len(dqn.exploration_rate_per_episode)), dqn.exploration_rate_per_episode, label=\"Exploration rate\")\n",
    "\n",
    "avg_rewards = []\n",
    "\n",
    "for i in range(len(dqn.rewards_per_episode)):\n",
    "    avg = []\n",
    "    for i,reward in enumerate(dqn.rewards_per_episode[max(0,i-4):min(i+5, len(dqn.rewards_per_episode))]):\n",
    "        avg.append(reward)\n",
    "    avg_rewards.append(sum(avg)/len(avg))\n",
    "\n",
    "plt.plot(range(len(avg_rewards)), avg_rewards, label=\"Moving average reward\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=250)\n",
    "plt.title(\"Exploration rate per episode\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Exploration rate\")\n",
    "plt.plot(range(len(dqn.exploration_rate_per_episode)), dqn.exploration_rate_per_episode, label=\"Exploration rate\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Window(\"Asteroids\", 60, 4.0) as window:\n",
    "    for step in dqn.rollout(0.3, 4).take(50000):\n",
    "        window(step.observation.numpy(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(dqn.rewards_per_episode)), dqn.rewards_per_episode, label=\"Total reward\")\n",
    "plt.plot(range(len(dqn.exploration_rate_per_episode)), dqn.exploration_rate_per_episode, label=\"Exploration rate\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(dqn.rewards_per_episode)), dqn.rewards_per_episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Window(\"Asteroids\", 60, 4.0) as window:\n",
    "    for i,step in dqn.rollout(0.7, frame_skips=4).take(3000).enumerate():\n",
    "        window(step.observation.numpy(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
