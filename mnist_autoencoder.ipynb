{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "from xai.policy import *\n",
    "from xai.buffer import Buffer\n",
    "from xai.bytes import GigaBytes\n",
    "from numpy import uint8\n",
    "from numpy.typing import NDArray\n",
    "from xai.mnist import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mnist\n",
    "import torch\n",
    "import random\n",
    "import shap\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = MNIST(5,2, \"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = mnist.train_images()\n",
    "\n",
    "buffer = Buffer((image for image in mnist), \"FIFO\", True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer[:50].enumerate().foreach(lambda ia: plt.imsave(f\"checkpoints/im{ia[0]}.png\", ia[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo.buffer.enumerate().foreach(lambda t: print(t[0],t[1].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.from_numpy(mnist.train_images()).to(device=\"cuda\")\n",
    "images = images.float()/255.0\n",
    "\n",
    "labels = torch.from_numpy(mnist.train_labels())\n",
    "labels_one_hot = torch.zeros((labels.shape[0],10)).float()\n",
    "labels_one_hot[torch.arange(0,labels.shape[0]),labels.int()] = 1.0\n",
    "\n",
    "images.shape, labels_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Policy.new((28,28),latent_dim, hidden_activation=\"ReLU\")\n",
    "decoder = Policy.new(encoder.output_dim,encoder.input_dim, hidden_activation=\"ReLU\")\n",
    "autoencoder = encoder + decoder\n",
    "autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = autoencoder.adam().fit(\n",
    "    X=images,\n",
    "    Y=images,\n",
    "    epochs=1500,\n",
    "    batch_size=128,\n",
    "    loss_criterion=\"MSELoss\",\n",
    "    verbose=True,\n",
    "    info=\"Autoencoder test\"\n",
    ")\n",
    "stats[5:].plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randint(0,len(images))\n",
    "X = images[idx]\n",
    "L = encoder(X)\n",
    "X_inv = autoencoder(X)\n",
    "digit = X_inv.tensor(True).argmax().item()\n",
    "\n",
    "fig = plt.figure(dpi=250, figsize=(10,6)) \n",
    "fig.add_subplot(3,5,1)\n",
    "plt.imshow(X.numpy(force=True), cmap=\"gray\") \n",
    "plt.axis('off')\n",
    "plt.title(f'$x$', size=7)\n",
    "\n",
    "fig.add_subplot(3,5, 2)\n",
    "plt.imshow(X_inv.numpy(), cmap=\"gray\") \n",
    "plt.axis('off')\n",
    "plt.title(f'$\\\\hat{{x}}^{{-1}}$', size=7)\n",
    "\n",
    "abs_saliency = X_inv.saliency(lambda t: t.sum())\n",
    "\n",
    "fig.add_subplot(3,5,3)\n",
    "plt.imshow(abs_saliency.numpy(force=True), cmap=\"gray\") \n",
    "plt.axis('off')\n",
    "plt.title(f\"$saliency(\\sum{{\\\\hat{{x^{{-1}}}}}})$\", size=7)\n",
    "\n",
    "gradients = X_inv.gradients(lambda t: t.sum())\n",
    "min,max = gradients.min(), gradients.max()\n",
    "if abs(max) > abs(min):\n",
    "    min = -max\n",
    "else:\n",
    "    max = -min\n",
    "red = torch.where(gradients < 0, gradients/min, torch.zeros_like(gradients))\n",
    "green = torch.where(gradients > 0, gradients/max, torch.zeros_like(gradients))\n",
    "saliency_with_corr = torch.zeros((28,28,3), dtype=torch.float32, device=\"cpu\")\n",
    "saliency_with_corr[:,:,0] = red\n",
    "saliency_with_corr[:,:,1] = green\n",
    "\n",
    "fig.add_subplot(3,5,4)\n",
    "plt.imshow(saliency_with_corr.numpy(force=True), cmap=\"gray\") \n",
    "plt.axis('off')\n",
    "plt.title(f\"$saliency(\\sum{{\\\\hat{{x}}^{{-1}}}})$\", size=7)\n",
    "\n",
    "shap_images = []\n",
    "for i in range(5):\n",
    "    gradients = L.gradients(lambda t: t[0])\n",
    "    min,max = gradients.min(), gradients.max()\n",
    "    if abs(max) > abs(min):\n",
    "        min = -max\n",
    "    else:\n",
    "        max = -min\n",
    "    red = torch.where(gradients < 0, gradients/min, torch.zeros_like(gradients))\n",
    "    green = torch.where(gradients > 0, gradients/max, torch.zeros_like(gradients))\n",
    "    latent_saliency = torch.zeros((28,28,3), dtype=torch.float32, device=\"cpu\")\n",
    "    latent_saliency[:,:,0] = red\n",
    "    latent_saliency[:,:,1] = green\n",
    "    fig.add_subplot(3,5,i+5)\n",
    "    plt.imshow(latent_saliency.numpy(force=True), cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(f'$saliency(l_{i})$', size=7)\n",
    "\n",
    "data = encoder(images).numpy()\n",
    "explainer = shap.PermutationExplainer(lambda t: decoder(torch.from_numpy(t)).numpy().reshape((-1,784)), masker=data)\n",
    "autoencoder_shap_values: shap.Explanation = explainer(data[idx:idx+1], max_evals=11)[0]\n",
    "autoencoder_shap_values = np.array(autoencoder_shap_values.values).reshape((latent_dim,28,28))\n",
    "\n",
    "min,max = autoencoder_shap_values.min(), autoencoder_shap_values.max()\n",
    "if abs(max) > abs(min):\n",
    "    min = -max\n",
    "else:\n",
    "    max = -min\n",
    "red = np.where(autoencoder_shap_values < 0, autoencoder_shap_values/min, np.zeros_like(autoencoder_shap_values))\n",
    "green = np.where(autoencoder_shap_values > 0, autoencoder_shap_values/max, np.zeros_like(autoencoder_shap_values))\n",
    "\n",
    "shap_images = []\n",
    "for i in range(5):\n",
    "    image = np.zeros((28,28,3), dtype=np.float32)\n",
    "    image[:,:,0] = red[i]\n",
    "    image[:,:,1] = green[i]\n",
    "    shap_images.append(image)\n",
    "    fig.add_subplot(3,5,i+10)\n",
    "    plt.imshow(shap_images[-1], cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(f'$shap(l_{i})$', size=7)\n",
    "\n",
    "fig.add_subplot(3,5,15)\n",
    "plt.imshow(np.stack(shap_images).mean(axis=0))\n",
    "plt.axis('off')\n",
    "plt.title(f'$\\\\frac{{\\sum_{{i=0}}^{{5}}{{shap(l_{{i}})}}}}{{N}}$', size=7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_head = Policy.new(encoder.output_dim,10, hidden_activation=\"ReLU\")\n",
    "classifier = encoder + classifier_head\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = classifier_head.adam().fit(\n",
    "    X=encoder(images),\n",
    "    Y=labels_one_hot,\n",
    "    epochs=5000,\n",
    "    batch_size=64,\n",
    "    loss_criterion=\"CrossEntropyLoss\",\n",
    "    verbose=True,\n",
    "    info=\"Classifier test\"\n",
    ")\n",
    "stats.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randint(0,len(images))\n",
    "X = images[idx]\n",
    "Y = classifier(X)\n",
    "digit = Y.tensor(True).argmax().item()\n",
    "\n",
    "fig = plt.figure(dpi=250, figsize=(10,5)) \n",
    "fig.add_subplot(4,7, 1)\n",
    "plt.imshow(X, cmap=\"gray\") \n",
    "plt.axis('off')\n",
    "plt.title(f'$x$', size=7)\n",
    "\n",
    "saliencies = []\n",
    "for i in range(10):\n",
    "    fig.add_subplot(4,7,i+2)\n",
    "    saliencies.append(Y.saliency(lambda t: t[i]))\n",
    "    plt.imshow(saliencies[-1], cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(f'$\\\\frac{{dx}}{{d\\hat y_{i}}}$', size=7)\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    gradients = Y.gradients(lambda t: t.sum())\n",
    "    min,max = gradients.min(), gradients.max()\n",
    "    if abs(max) > abs(min):\n",
    "        min = -max\n",
    "    else:\n",
    "        max = -min\n",
    "    red = torch.where(gradients < 0, gradients/min, torch.zeros_like(gradients))\n",
    "    green = torch.where(gradients > 0, gradients/max, torch.zeros_like(gradients))\n",
    "    saliency_with_corr = torch.zeros((28,28,3), dtype=torch.float32, device=\"cpu\")\n",
    "    saliency_with_corr[:,:,0] = red\n",
    "    saliency_with_corr[:,:,1] = green\n",
    "    fig.add_subplot(4,7,i+12)\n",
    "    plt.imshow(saliency_with_corr, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(f'$\\\\frac{{dx}}{{d\\hat y_{i}}}$', size=7)\n",
    "\n",
    "\n",
    "data = encoder(images).numpy()\n",
    "explainer = shap.PermutationExplainer(lambda t: classifier_head(torch.from_numpy(t)).numpy().reshape((-1,10)), masker=data)\n",
    "classifier_head_shap_values: shap.Explanation = explainer(data[idx:idx+1], max_evals=11)[0]\n",
    "classifier_head_shap_values = np.array(classifier_head_shap_values.values).reshape((latent_dim,10))\n",
    "\n",
    "classifier_head_shap_min, classifier_head_shap_max = classifier_head_shap_values.min(), classifier_head_shap_values.max()\n",
    "if abs(classifier_head_shap_max) > abs(classifier_head_shap_min):\n",
    "    classifier_head_shap_min = -classifier_head_shap_max\n",
    "else:\n",
    "    classifier_head_shap_max = -classifier_head_shap_min\n",
    "\n",
    "\n",
    "negative = np.where(classifier_head_shap_values < 0, classifier_head_shap_values / classifier_head_shap_min, np.zeros_like(classifier_head_shap_values))\n",
    "negative = negative / negative.sum(axis=0)\n",
    "\n",
    "positive = np.where(classifier_head_shap_values > 0, classifier_head_shap_values / classifier_head_shap_max, np.zeros_like(classifier_head_shap_values))\n",
    "positive = positive / positive.sum(axis=0)\n",
    "\n",
    "positive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randint(0,len(images))\n",
    "X = images[idx]\n",
    "X_inv = autoencoder(X)\n",
    "digit = X_inv.tensor().argmax().item()\n",
    "\n",
    "fig = plt.figure(dpi=250, figsize=(10,4)) \n",
    "fig.add_subplot(2,6,1)\n",
    "plt.imshow(X, cmap=\"gray\") \n",
    "plt.axis('off')\n",
    "plt.title(f'$x$', size=7)\n",
    "\n",
    "fig.add_subplot(2,6, 2)\n",
    "plt.imshow(X_inv.numpy(), cmap=\"gray\") \n",
    "plt.axis('off')\n",
    "plt.title(f'$\\\\hat{{x^{{-1}}}}$', size=7)\n",
    "\n",
    "abs_saliency = X_inv.saliency(lambda t: t.sum())\n",
    "\n",
    "fig.add_subplot(2,6,3)\n",
    "plt.imshow(abs_saliency, cmap=\"gray\") \n",
    "plt.axis('off')\n",
    "plt.title(f\"Absolute saliency\", size=7)\n",
    "\n",
    "gradients = X_inv.gradients(lambda t: t.sum())\n",
    "min,max = gradients.min(), gradients.max()\n",
    "if abs(max) > abs(min):\n",
    "    min = -max\n",
    "else:\n",
    "    max = -min\n",
    "red = torch.where(gradients < 0, gradients/min, torch.zeros_like(gradients))\n",
    "green = torch.where(gradients > 0, gradients/max, torch.zeros_like(gradients))\n",
    "saliency_with_corr = torch.zeros((28,28,3), dtype=torch.float32, device=\"cpu\")\n",
    "saliency_with_corr[:,:,0] = red\n",
    "saliency_with_corr[:,:,1] = green\n",
    "\n",
    "fig.add_subplot(2,6,4)\n",
    "plt.imshow(saliency_with_corr, cmap=\"gray\") \n",
    "plt.axis('off')\n",
    "plt.title(f\"Saliency with anti-correlation\", size=7)\n",
    "\n",
    "data = encoder(images).numpy()\n",
    "explainer = shap.PermutationExplainer(lambda t: decoder(torch.from_numpy(t)).numpy().reshape((-1,784)), masker=data)\n",
    "autoencoder_shap_values: shap.Explanation = explainer(data[idx:idx+1], max_evals=11)[0]\n",
    "autoencoder_shap_values = np.array(autoencoder_shap_values.values).reshape((latent_dim,28,28))\n",
    "\n",
    "shap_sum = autoencoder_shap_values.sum(0)\n",
    "min,max = shap_sum.min(), shap_sum.max()\n",
    "if abs(max) > abs(min):\n",
    "    min = -max\n",
    "else:\n",
    "    max = -min\n",
    "blue = np.where(autoencoder_shap_values < 0, autoencoder_shap_values/min, np.zeros_like(autoencoder_shap_values))\n",
    "red = np.where(autoencoder_shap_values > 0, autoencoder_shap_values/max, np.zeros_like(autoencoder_shap_values))\n",
    "\n",
    "shap_images = []\n",
    "for i in range(5):\n",
    "    image = np.zeros((28,28,3), dtype=np.float32)\n",
    "    image[:,:,0] = red[i]\n",
    "    image[:,:,2] = blue[i]\n",
    "    shap_images.append(image)\n",
    "    fig.add_subplot(2,6,i+5)\n",
    "    plt.imshow(shap_images[-1], cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(f'$shap(l_{{i}})_{i}$', size=7)\n",
    "\n",
    "\n",
    "image = np.zeros((28,28,3), dtype=np.float32)\n",
    "image[:,:,2] = np.where(shap_sum < 0, -shap_sum, np.zeros_like(shap_sum))\n",
    "image[:,:,0] = np.where(shap_sum > 0, shap_sum, np.zeros_like(shap_sum))\n",
    "\n",
    "fig.add_subplot(2,6,10)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.title(f'$\\sum_{{n=0}}^{{N}}{{shap(l_{{i}})_{{n}}}}$', size=7)\n",
    "\n",
    "fig.add_subplot(2,6,11)\n",
    "plt.imshow(image.mean(axis=2), cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "plt.title(f'$\\sum_{{n=0}}^{{N}}{{shap(l_{{i}})_{{n}}}}$', size=7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
