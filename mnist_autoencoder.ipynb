{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xai.mnist import MNIST\n",
    "from xai.explainer import PermutationExplainer, ExactExplainer, KernelExplainer, DeepExplainer\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xai.mnist.MNIST at 0x7f3e96481810>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_dim = 32\n",
    "device = \"cuda\"\n",
    "\n",
    "mnist = MNIST((latent_dim,), device=device, hidden_layers=2)\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MNIST' object has no attribute '_classifier_head_explainers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43mmnist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_autoencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10_000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_criterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMSELoss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_cont\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m750\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMnist autoencoder train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m stats[\u001b[38;5;241m5\u001b[39m:]\u001b[38;5;241m.\u001b[39mplot_loss()\n",
      "File \u001b[0;32m~/master-project/xai/mnist.py:211\u001b[0m, in \u001b[0;36mMNIST.fit_autoencoder\u001b[0;34m(self, epochs, batch_size, loss_criterion, early_stop_cont, verbose, info)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_autoencoder\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m    204\u001b[0m                     epochs: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m    205\u001b[0m                     batch_size: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m                     verbose: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    209\u001b[0m                     info: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TrainStats:\n\u001b[1;32m    210\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_explainers\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m--> 211\u001b[0m       \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_classifier_head_explainers\u001b[49m\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m    212\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoencoder\u001b[38;5;241m.\u001b[39madam()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    213\u001b[0m          X_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data,\n\u001b[1;32m    214\u001b[0m          Y_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m          info\u001b[38;5;241m=\u001b[39minfo\n\u001b[1;32m    223\u001b[0m      )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MNIST' object has no attribute '_classifier_head_explainers'"
     ]
    }
   ],
   "source": [
    "stats = mnist.fit_autoencoder(\n",
    "    epochs=10_000,\n",
    "    batch_size=256,\n",
    "    loss_criterion=\"MSELoss\",\n",
    "    early_stop_cont=750,\n",
    "    verbose=True,\n",
    "    info=\"Mnist autoencoder train\"\n",
    ")\n",
    "stats[5:].plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = mnist.fit_classifier_head(\n",
    "    epochs=10_000,\n",
    "    batch_size=256,\n",
    "    early_stop_cont=750,\n",
    "    verbose=True,\n",
    "    info=\"Mnist classifier-head train\"\n",
    ")\n",
    "stats[5:].plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,15), dpi=250) \n",
    "rows = 10\n",
    "columns = latent_dim + 4\n",
    "\n",
    "for row in range(rows):\n",
    "    slot = row*columns\n",
    "\n",
    "    sample,label = mnist.get_sample(digit=row)\n",
    "    sample = sample.numpy(force=True)\n",
    "    label = int(label.item())\n",
    "    predict = mnist(sample)\n",
    "    recon = predict.reconstruction().numpy(force=True)\n",
    "    digit = predict.digits()[0]\n",
    "    cls = predict.classification().tolist()\n",
    "\n",
    "    recon_xai = predict.explain(\"reconstruction\", \"permutation\")\n",
    "    feature_sum = recon_xai.feature_sum()\n",
    "    norm = max([recon_xai.abs().max(), feature_sum.abs().max()])\n",
    "\n",
    "\n",
    "    fig.add_subplot(rows,columns,slot+1)\n",
    "    plt.imshow(sample, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Original ($X={{{label}}}$)\", size=8)\n",
    "        \n",
    "    fig.add_subplot(rows,columns,slot+2)\n",
    "    plt.imshow(recon, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Reconstruction ($\\hat{{X}}$)\", size=8)\n",
    "\n",
    "    for j,image in enumerate(recon_xai.to_rgb(norm)):\n",
    "        fig.add_subplot(rows,columns,slot+j+3)\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"$l_{{{j}}}$\", size=8)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,15), dpi=250) \n",
    "rows = 10\n",
    "columns = 15\n",
    "\n",
    "for row in range(rows):\n",
    "    slot = row*columns\n",
    "\n",
    "    sample,label = mnist.get_sample(digit=row)\n",
    "    sample = sample.numpy(force=True)\n",
    "    label = int(label.item())\n",
    "    predict = mnist(sample)\n",
    "    recon = predict.reconstruction().numpy(force=True)\n",
    "    digit = predict.digits()[0]\n",
    "    cls = predict.classification().tolist()\n",
    "\n",
    "    recon_xai = predict.explain(\"reconstruction\", \"permutation\").shap_values\n",
    "    cls_xai = predict.explain(\"classification\", \"permutation\").shap_values\n",
    "\n",
    "    fig.add_subplot(rows,columns,slot+1)\n",
    "    plt.imshow(sample, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Original ($X={{{label}}}$)\", size=8)\n",
    "        \n",
    "    fig.add_subplot(rows,columns,slot+2)\n",
    "    plt.imshow(recon, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Reconstruction ($\\hat{{X}}$)\", size=8)\n",
    "\n",
    "    shaps = []\n",
    "        \n",
    "    for j in range(10):\n",
    "        shap = np.zeros_like(recon_xai)\n",
    "        for k in range(latent_dim):\n",
    "            shap[k] = recon_xai[k] * cls_xai[k,j]\n",
    "\n",
    "        shap = shap.sum(axis=0)\n",
    "        shaps.append(shap)\n",
    "\n",
    "    shaps = np.stack(shaps)\n",
    "    delta_shap: np.ndarray = shaps[label] - (shaps[:label].sum(axis=0) + shaps[label+1:].sum(axis=0))\n",
    "    shap_sum = shaps.sum(axis=0)\n",
    "    norm = max([np.max(np.abs(shaps)), np.max(np.abs(delta_shap)), np.max(np.abs(shap_sum))])\n",
    "\n",
    "    for j,shap in enumerate(shaps):\n",
    "        fig.add_subplot(rows,columns,slot+j+3)\n",
    "        im = np.zeros((28,28,3), dtype=np.float32)\n",
    "        red = np.where(shap > 0, shap/norm, np.zeros_like(shap))\n",
    "        blue = np.where(shap < 0, -shap/norm, np.zeros_like(shap))\n",
    "        im[:,:,0] = red\n",
    "        im[:,:,2] = blue\n",
    "        plt.imshow(im)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Class: {j} ($C_{j}$)\\n${cls[j]*100:.2f}$%\", size=8)\n",
    "\n",
    "    \n",
    "    fig.add_subplot(rows,columns,slot+j+4)\n",
    "    im = np.zeros((28,28,3), dtype=np.float32)\n",
    "    red = np.where(shap_sum > 0, shap_sum/norm, np.zeros_like(shap_sum))\n",
    "    blue = np.where(shap_sum < 0, -shap_sum/norm, np.zeros_like(shap_sum))\n",
    "    im[:,:,0] = red\n",
    "    im[:,:,2] = blue\n",
    "    plt.imshow(im)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"$\\sum_{{i={0}}}^{{{rows-1}}}{{C_i}}$\", size=8)\n",
    "\n",
    "    fig.add_subplot(rows,columns,slot+j+5)\n",
    "    im = np.zeros((28,28,3), dtype=np.float32)\n",
    "    red = np.where(delta_shap > 0, delta_shap/norm, np.zeros_like(delta_shap))\n",
    "    blue = np.where(delta_shap < 0, -delta_shap/norm, np.zeros_like(delta_shap))\n",
    "    im[:,:,0] = red\n",
    "    im[:,:,2] = blue\n",
    "    plt.imshow(im)\n",
    "    plt.axis('off')\n",
    "    if row == 0:\n",
    "        plt.title(f\"$C_{{{label}}} - \\sum_{{i={1}}}^{{{rows-1}}}{{C_i}}$\", size=8)\n",
    "    elif row == (rows - 1):\n",
    "        plt.title(f\"$C_{{{label}}} - \\sum_{{i={0}}}^{{{rows-2}}}{{C_i}}$\", size=8)\n",
    "    else:\n",
    "        plt.title(f\"$C_{{{label}}} - (\\sum_{{i={0}}}^{{{label-1}}}{{C_i}} + \\sum_{{i={label+1}}}^{{{rows-1}}}{{C_i}})$\", size=8)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,15), dpi=250) \n",
    "rows = 10\n",
    "columns = 15\n",
    "explainer = KernelExplainer(mnist, mnist.val_data)\n",
    "\n",
    "for row in range(rows):\n",
    "    slot = row*columns\n",
    "\n",
    "    sample,label = mnist.get_sample(digit=row)\n",
    "    sample = sample.numpy(force=True)\n",
    "    label = int(label.item())\n",
    "    predict = mnist(sample)\n",
    "    recon = predict.reconstruction().numpy(force=True)\n",
    "    digit = predict.digits()[0]\n",
    "    cls = predict.classification().tolist()\n",
    "\n",
    "    xai = np.moveaxis(explainer.explain(sample, verbose=True)[0].shap_values, source=2, destination=0)\n",
    "\n",
    "    fig.add_subplot(rows,columns,slot+1)\n",
    "    plt.imshow(sample, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Original ($X={{{label}}}$)\", size=8)\n",
    "        \n",
    "    fig.add_subplot(rows,columns,slot+2)\n",
    "    plt.imshow(recon, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Reconstruction ($\\hat{{X}}$)\", size=8)\n",
    "\n",
    "    shaps = np.stack(xai)\n",
    "    delta_shap: np.ndarray = shaps[label] - (shaps[:label].sum(axis=0) + shaps[label+1:].sum(axis=0))\n",
    "    shap_sum = shaps.sum(axis=0)\n",
    "    norm = max([np.max(np.abs(shaps)), np.max(np.abs(delta_shap)), np.max(np.abs(shap_sum))])\n",
    "\n",
    "    for j,shap in enumerate(shaps):\n",
    "        fig.add_subplot(rows,columns,slot+j+3)\n",
    "        im = np.zeros((28,28,3), dtype=np.float32)\n",
    "        red = np.where(shap > 0, shap/norm, np.zeros_like(shap))\n",
    "        blue = np.where(shap < 0, -shap/norm, np.zeros_like(shap))\n",
    "        im[:,:,0] = red\n",
    "        im[:,:,2] = blue\n",
    "        plt.imshow(im)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Class: {j} ($C_{j}$)\\n${cls[j]*100:.2f}$%\", size=8)\n",
    "\n",
    "    \n",
    "    fig.add_subplot(rows,columns,slot+j+4)\n",
    "    im = np.zeros((28,28,3), dtype=np.float32)\n",
    "    red = np.where(shap_sum > 0, shap_sum/norm, np.zeros_like(shap_sum))\n",
    "    blue = np.where(shap_sum < 0, -shap_sum/norm, np.zeros_like(shap_sum))\n",
    "    im[:,:,0] = red\n",
    "    im[:,:,2] = blue\n",
    "    plt.imshow(im)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"$\\sum_{{i={0}}}^{{{rows-1}}}{{C_i}}$\", size=8)\n",
    "\n",
    "    fig.add_subplot(rows,columns,slot+j+5)\n",
    "    im = np.zeros((28,28,3), dtype=np.float32)\n",
    "    red = np.where(delta_shap > 0, delta_shap/norm, np.zeros_like(delta_shap))\n",
    "    blue = np.where(delta_shap < 0, -delta_shap/norm, np.zeros_like(delta_shap))\n",
    "    im[:,:,0] = red\n",
    "    im[:,:,2] = blue\n",
    "    plt.imshow(im)\n",
    "    plt.axis('off')\n",
    "    if row == 0:\n",
    "        plt.title(f\"$C_{{{label}}} - \\sum_{{i={1}}}^{{{rows-1}}}{{C_i}}$\", size=8)\n",
    "    elif row == (rows - 1):\n",
    "        plt.title(f\"$C_{{{label}}} - \\sum_{{i={0}}}^{{{rows-2}}}{{C_i}}$\", size=8)\n",
    "    else:\n",
    "        plt.title(f\"$C_{{{label}}} - (\\sum_{{i={0}}}^{{{label-1}}}{{C_i}} + \\sum_{{i={label+1}}}^{{{rows-1}}}{{C_i}})$\", size=8)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "\n",
    "for i in range(rows):\n",
    "    samples.append(mnist.get_sample(digit=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,15), dpi=250) \n",
    "rows = 10\n",
    "columns = 15\n",
    "explainer = DeepExplainer(mnist, mnist.val_data)\n",
    "\n",
    "for row in range(rows):\n",
    "    slot = row*columns\n",
    "\n",
    "    sample,label = samples[row]\n",
    "    sample = sample.numpy(force=True)\n",
    "    label = int(label.item())\n",
    "    predict = mnist(sample)\n",
    "    recon = predict.reconstruction().numpy(force=True)\n",
    "    digit = predict.digits()[0]\n",
    "    cls = predict.classification().tolist()\n",
    "\n",
    "    xai = explainer.explain(sample)[0].reshape((-1,28,28))\n",
    "\n",
    "    fig.add_subplot(rows,columns,slot+1)\n",
    "    plt.imshow(sample, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Original ($X={{{label}}}$)\", size=8)\n",
    "        \n",
    "    fig.add_subplot(rows,columns,slot+2)\n",
    "    plt.imshow(recon, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Reconstruction ($\\hat{{X}}$)\", size=8)\n",
    "\n",
    "    shaps = np.stack(xai)\n",
    "    delta_shap: np.ndarray = shaps[label] - (shaps[:label].sum(axis=0) + shaps[label+1:].sum(axis=0))\n",
    "    shap_sum = shaps.sum(axis=0)\n",
    "    norm = max([np.max(np.abs(shaps))])\n",
    "\n",
    "    for j,shap in enumerate(shaps):\n",
    "        fig.add_subplot(rows,columns,slot+j+3)\n",
    "        im = np.zeros((28,28,3), dtype=np.float32)\n",
    "        red = np.where(shap > 0, shap/norm, np.zeros_like(shap))\n",
    "        blue = np.where(shap < 0, -shap/norm, np.zeros_like(shap))\n",
    "        im[:,:,0] = red\n",
    "        im[:,:,2] = blue\n",
    "        plt.imshow(im)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Class: {j} ($C_{j}$)\\n${cls[j]*100:.2f}$%\", size=8)\n",
    "\n",
    "    norm = max([np.max(np.abs(shap_sum))])\n",
    "    fig.add_subplot(rows,columns,slot+j+4)\n",
    "    im = np.zeros((28,28,3), dtype=np.float32)\n",
    "    red = np.where(shap_sum > 0, shap_sum/norm, np.zeros_like(shap_sum))\n",
    "    blue = np.where(shap_sum < 0, -shap_sum/norm, np.zeros_like(shap_sum))\n",
    "    im[:,:,0] = red\n",
    "    im[:,:,2] = blue\n",
    "    plt.imshow(im)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"$\\sum_{{i={0}}}^{{{rows-1}}}{{C_i}}$\", size=8)\n",
    "\n",
    "    norm = max([np.max(np.abs(delta_shap))])\n",
    "    fig.add_subplot(rows,columns,slot+j+5)\n",
    "    im = np.zeros((28,28,3), dtype=np.float32)\n",
    "    red = np.where(delta_shap > 0, delta_shap/norm, np.zeros_like(delta_shap))\n",
    "    blue = np.where(delta_shap < 0, -delta_shap/norm, np.zeros_like(delta_shap))\n",
    "    im[:,:,0] = red\n",
    "    im[:,:,2] = blue\n",
    "    plt.imshow(im)\n",
    "    plt.axis('off')\n",
    "    if row == 0:\n",
    "        plt.title(f\"$C_{{{label}}} - \\sum_{{i={1}}}^{{{rows-1}}}{{C_i}}$\", size=8)\n",
    "    elif row == (rows - 1):\n",
    "        plt.title(f\"$C_{{{label}}} - \\sum_{{i={0}}}^{{{rows-2}}}{{C_i}}$\", size=8)\n",
    "    else:\n",
    "        plt.title(f\"$C_{{{label}}} - (\\sum_{{i={0}}}^{{{label-1}}}{{C_i}} + \\sum_{{i={label+1}}}^{{{rows-1}}}{{C_i}})$\", size=8)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,15), dpi=250) \n",
    "rows = 10\n",
    "columns = 15\n",
    "\n",
    "for row in range(rows):\n",
    "    slot = row*columns\n",
    "\n",
    "    sample,label = samples[row]\n",
    "    sample = sample.numpy(force=True)\n",
    "    label = int(label.item())\n",
    "    predict = mnist(sample)\n",
    "    recon = predict.reconstruction().numpy(force=True)\n",
    "    digit = predict.digits()[0]\n",
    "    cls = predict.classification().tolist()\n",
    "\n",
    "    recon_xai = predict.explain(\"reconstruction\", \"permutation\")\n",
    "    cls_xai = predict.explain(\"classification\", \"permutation\")\n",
    "\n",
    "\n",
    "    fig.add_subplot(rows,columns,slot+1)\n",
    "    plt.imshow(sample, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Original ($X={{{label}}}$)\", size=8)\n",
    "        \n",
    "    fig.add_subplot(rows,columns,slot+2)\n",
    "    plt.imshow(recon, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Reconstruction ($\\hat{{X}}$)\", size=8)\n",
    "        \n",
    "    shaps = cls_xai.combine(recon_xai).shap_values\n",
    "\n",
    "    delta_shap: np.ndarray = shaps[label] - (shaps[:label].sum(axis=0) + shaps[label+1:].sum(axis=0))\n",
    "    shap_sum = shaps.sum(axis=0)\n",
    "    norm = max([np.max(np.abs(shaps)), np.max(np.abs(delta_shap)), np.max(np.abs(shap_sum))])\n",
    "\n",
    "    for j,shap in enumerate(shaps):\n",
    "        fig.add_subplot(rows,columns,slot+j+3)\n",
    "        im = np.zeros((28,28,3), dtype=np.float32)\n",
    "        red = np.where(shap > 0, shap/norm, np.zeros_like(shap))\n",
    "        blue = np.where(shap < 0, -shap/norm, np.zeros_like(shap))\n",
    "        im[:,:,0] = red\n",
    "        im[:,:,2] = blue\n",
    "        plt.imshow(im)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Class: {j} ($C_{j}$)\\n${cls[j]*100:.2f}$%\", size=8)\n",
    "\n",
    "    \n",
    "    fig.add_subplot(rows,columns,slot+j+4)\n",
    "    im = np.zeros((28,28,3), dtype=np.float32)\n",
    "    red = np.argwhere(shap_sum > 0)\n",
    "    blue = np.argwhere(shap_sum < 0)\n",
    "    im[:,:,0]\n",
    "    red = np.where(shap_sum > 0, shap_sum/norm, np.zeros_like(shap_sum))\n",
    "    blue = np.where(shap_sum < 0, -shap_sum/norm, np.zeros_like(shap_sum))\n",
    "    im[:,:,0] = red\n",
    "    im[:,:,2] = blue\n",
    "    plt.imshow(im)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"$\\sum_{{i={0}}}^{{{rows-1}}}{{C_i}}$\", size=8)\n",
    "\n",
    "    fig.add_subplot(rows,columns,slot+j+5)\n",
    "    im = np.zeros((28,28,3), dtype=np.float32)\n",
    "    red = np.where(delta_shap > 0, delta_shap/norm, np.zeros_like(delta_shap))\n",
    "    blue = np.where(delta_shap < 0, -delta_shap/norm, np.zeros_like(delta_shap))\n",
    "    im[:,:,0] = red\n",
    "    im[:,:,2] = blue\n",
    "    plt.imshow(im)\n",
    "    plt.axis('off')\n",
    "    if row == 0:\n",
    "        plt.title(f\"$C_{{{label}}} - \\sum_{{i={1}}}^{{{rows-1}}}{{C_i}}$\", size=8)\n",
    "    elif row == (rows - 1):\n",
    "        plt.title(f\"$C_{{{label}}} - \\sum_{{i={0}}}^{{{rows-2}}}{{C_i}}$\", size=8)\n",
    "    else:\n",
    "        plt.title(f\"$C_{{{label}}} - (\\sum_{{i={0}}}^{{{label-1}}}{{C_i}} + \\sum_{{i={label+1}}}^{{{rows-1}}}{{C_i}})$\", size=8)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
